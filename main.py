from database.store import save_thread
from scraper.fetcher import fetch_page_html
from scraper.parser import extract_data_from_html

def run_pipeline(url: str):
    print("\nğŸš€ Pipeline started.")

    # Step 1: fetch HTML
    html = fetch_page_html(url)
    if not html:
        print("âŒ ç„¡æ³•æŠ“å– HTML")
        return

    print("ğŸ§© HTML OKï¼Œé–‹å§‹è§£æ...")

    # Step 2: parse
    data = extract_data_from_html(html, url)

    # Step 3: result preview
    print("\n===== çµæœé è¦½ =====")
    print("ä½œè€…:", data["author"])
    print("ä¸»æ–‡ï¼ˆä¹¾æ·¨ï¼‰:", data["post_text"][:200], "...")
    print("Like:", data["metrics"]["likes"])
    print("Views:", data["metrics"]["views"])
    print("Reply ç¸½æ•¸ (UI):", data["metrics"]["reply_count"])
    print("Repost ç¸½æ•¸ (UI):", data["metrics"]["repost_count"])
    print("Share ç¸½æ•¸ (UI):", data["metrics"]["share_count"])
    print("å¯¦éš›æŠ“åˆ°ç•™è¨€æ¨£æœ¬:", len(data["comments"]))
    print("====================")

    # Step 4: save to DB
    save_thread(data)

    # å°ç•™è¨€åˆ—è¡¨
    print("\n===== ç•™è¨€ Sample =====")
    for idx, c in enumerate(data["comments"], start=1):
        print(f"\n--- Comment #{idx} ---")
        print("User:", c["user"])
        print("Likes:", c["likes"])
        print("Text:", c["text"])
    print("======================\n")


if __name__ == "__main__":
    mode = input("è¼¸å…¥æ¨¡å¼: (1) å–®ä¸€URL / (2) å¤šæ¢URLåˆ—è¡¨ [1/2]ï¼š").strip()

    if mode == "2":
        print("è«‹è¼¸å…¥å¤šæ¢ URLï¼Œæ¯è¡Œä¸€æ¢ï¼Œè¼¸å…¥ç©ºè¡ŒçµæŸï¼š")
        urls = []
        while True:
            line = input().strip()
            if not line:
                break
            # è‡ªå‹• threads.com â†’ threads.net
            if "threads.com" in line:
                line = line.replace("threads.com", "threads.net")
                print(f"ğŸ” åµæ¸¬åˆ° threads.comï¼Œå·²è‡ªå‹•æ”¹æˆï¼š{line}")
            urls.append(line)

        for url in urls:
            print("\n==============================")
            print(f"æ­£åœ¨è™•ç†: {url}")
            run_pipeline(url)
        print("\nğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆã€‚")
    else:
        url = input("è«‹è¼¸å…¥ Threads URLï¼š").strip()

        # è‡ªå‹• threads.com â†’ threads.net
        if "threads.com" in url:
            url = url.replace("threads.com", "threads.net")
            print(f"ğŸ” åµæ¸¬åˆ° threads.comï¼Œå·²è‡ªå‹•æ”¹æˆï¼š{url}")

        run_pipeline(url)
